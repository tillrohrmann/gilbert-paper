%!TEX root=paper.tex
\section{Gilbert's Language and Features}
\label{sec:gilbertLanguage}

Gilbert's language has been strongly inspired by MATLAB which should ease its adoption.
The language is a fully functional subset of MATLAB and its grammar is specified in \cite{masterthesis}.
The elementary data type is the matrix.
Gilbert supports arbitrary $2$-dimensional matrices whose elements can be \emph{double} or \emph{boolean}.
Vectors are not represented by a special type but instead are treated as a single column/row matrix.
Additionally, scalar \emph{double}, \emph{boolean} and string values are supported.

Gilbert also implements cell array types.
A cell array is defined using curly braces and commas to separate individual values.
The cells can be accessed by an index appended in curly braces to the cell array variable.
\Cref{lst:cellArray} shows how to define and access them.

\begin{listing}[!h]
  \begin{CenteredBox}
    \begin{lstlisting}[language=Matlab,
        commentstyle=\color{black},
        stringstyle=\color{black},
    ]
c = {true, 2*2, 'cell', 'array'};
b = c{1} & false; % = false
d = c{2} ^ 2; % = 16
s = {c{4}, c{3}}; % = {'array', 'cell'} 
    \end{lstlisting}
  \end{CenteredBox}
  \caption{Cell array usage in Gilbert. Definition of a 4 element cell array which is accessed subsequently.}
  \label{lst:cellArray}
\end{listing}

Gilbert supports the basic linear algebra operations defined on matrices and scalars.
They include among others the common operations \code{+}, \code{-}, \code{/} and \code{*}, whereas \code{*} denotes the matrix-matrix multiplication and all other operations are interpreted cellwisely.
The cellwise multiplication is indicated by a point preceding the operator.
Gilbert also supports comparisons operators such as \code{>}, \code{>=}, \code{==} and \code{\textasciitilde=}.

Besides the basic arithmetic operations, the user can also define named functions and anonymous functions.
The syntax of anonymous functions adheres to the MATLAB syntax: \code{@(x,y) x*x + y*y}.

An important aspect of MATLAB are loops.
MATLAB permits the user to express \code{for} and \code{while} loops.
However, these loops can have side effects.
The problem of parallelization of iterations with side effects is that the referenced external state has to be maintained.
This circumstance makes preprocessing and execution unnecessarily complex.
Gilbert offers a fixpoint operator \code{fixpoint}, which iteratively applies a given update function $f$ on the previous result of $f$, starting with an initial value $x$ at iteration $0$.

\begin{displaymath}
  n^{th}\text{ iteration}\equiv\underbrace{f(f(\ldots(f(x))\ldots))}_{\text{$n$ times}}
\end{displaymath}

In order to terminate the fixpoint operation, the operator provides two mechanisms.
The user has to specify a maximum number \code{m} of iterations.
Additionally, the user can provide a convergence function \code{c} to the fixpoint operator.
The convergence function is called with the previous and current fixpoint value and returns a boolean value.
Thus, the fixpoint operator terminates either if convergence was detected or if the maximum number of iterations is exceeded.
\begin{equation}
fixpoint: \underbrace{T}_{\text{\code{x}}} \times \left( \underbrace{T \rightarrow T}_{\text{\code{f}}} \right) \times \underbrace{\mathbb{N}}_{\text{\code{m}}} \times \left(\underbrace{T\times T \rightarrow \mathbb{B}}_{\text{\code{c}}} \right) \rightarrow T
\label{eqn:fixpoint}
\end{equation}
with $T$ being a generic type variable.

In fact, the fixpoint operator replaces iterations by recursions whereas the update function $f$ is pure.
At this point Gilbert breaks with existing MATLAB code.
However, all MATLAB loops can be expressed via the fixpoint operator by passing the loop's closure to the update function \cref{fig:for2Fixpoint}.

\begin{listing}
  \centering
  \begin{sublisting}{.4\linewidth}
    \begin{lstlisting}[language=Matlab,
      commentstyle=\color{black},
      stringstyle=\color{black},
      keywordstyle=\color{black}\bfseries,
    ]
A = 0;
for i = 1:10
  A = A + i;
end
    \end{lstlisting}
    \caption{For loop}
    \label[listing]{fig:for2Fixpoint:for}
  \end{sublisting}
  \begin{sublisting}{.5\linewidth}
      \begin{lstlisting}[language=Matlab]
f = @(x) ...
  {x{1} + x{2}, x{2} + 1};
r = fixpoint({0,1}, f, 10);
A = r{1};
    \end{lstlisting}
    \caption{Fixpoint}
    \label[listing]{fig:for2Fixpoint:fixpoint}
  \end{sublisting}
  \caption{Transformation from Matlab for loop \subref{fig:for2Fixpoint:for} to Gilbert fixpoint \subref{fig:for2Fixpoint:fixpoint} formulation. Essentially, all iteration data is combined and passed as a cell array value to the update function.}
  \label{fig:for2Fixpoint}
\end{listing}

\subsection{Gilbert Typing System}
\label{sec:gilberttyping}

MATLAB belongs to the class of dynamically typed languages and Gilbert requires type information for its parallel execution.
The parallel data processing systems, used to run Gilbert programs, have to know which data types are passed from one worker node to another.
Therefore, the MATLAB language has to be enriched with type information.
We infer this type information using the Hindley-Milner (HM) type system~\cite{hindley:tams1969a,milner:jcss1978a} and a slightly derived form of algorithm W~\cite{damas:1982a} for type inference.

In case that the type inference algorithm cannot properly infer the types, there has to be a way to resolve this problem.
We decided to pursue a similar approach as \cite{furr:2009a}.
\cite{furr:2009a} added type information to Ruby by adding special comments to the respective code sections without breaking it.

\subsubsection{Function Overloading}

MATLAB's basic operators, such as \code{+}, \code{-}, \code{/} and \code{*}, for example, are overloaded.
They can be applied to matrices, scalars as well as mixture of both data types.
That makes it very convenient to express mathematical problems, but from a programmer's point of view it causes some hardships.
Originally, HM cannot deal with overloaded functions properly, because it assumes that each function has an unique type.
In order to extend HM's capabilities, we allowed each function symbol to have a list of signatures.
In the case of \code{+}, the list of signatures would consist of 
\begin{eqnarray*}
matrix[double] \times matrix[double] &\rightarrow& matrix[double]\\
matrix[double] \times double &\rightarrow& matrix[double]\\
double \times matrix[double] &\rightarrow& matrix[double]\\
double \times double &\rightarrow& double
\end{eqnarray*}

In order to solve the typing problem, the inference algorithm has to resolve this ambiguity.
Having complete knowledge of the argument types is enough to select the appropriate signature.
Sometimes even partial knowledge is sufficient.
However, if this information is missing, Gilbert has to apply a heuristic to make the typing expression well-formed.
The heuristic selects the first entry in the list of signatures.

\subsubsection{Matrix Dimension Inference}
\label{sec:MatrixDimensionInference}

Matrices constitute the elementary data type in our linear algebra environment.
Besides its element type, a matrix is also defined by its size.
In the context of program execution, knowledge about matrix sizes can help to optimize the evaluation.
For instance, consider a threefold matrix multiplication $A\times B\times C$.
The multiplication can be evaluated in two different ways: $(A\times B)\times C$ and $A\times(B\times C)$.
For certain matrix sizes one way might be infeasible whereas the other way can be calculated efficiently due to the matrix size of the intermediate result $(A\times B)$ or $(B\times C)$.

By knowing the matrix sizes, Gilbert can choose the most efficient strategy to calculate the requested result.
Another advantage is that we can decide whether to carry out the computation in-core or in parallel depending on the matrix sizes.
Sometimes the benefit of parallel execution is smaller than the initial communication overhead and thus it would be wiser to execute the calculation locally.
Furthermore, it can be helpful for data partitioning on a large cluster and to decide on a blocking strategy with respect to the algebraic operations.
Therefore, we extended the HM type inference to also infer matrix sizes where possible.

Gilbert's matrix type is defined as 
\begin{displaymath}
MatrixType(\underbrace{\tau}_{\text{Element type}},\underbrace{\nu}_{\text{Number of rows}},\underbrace{\nu}_{\text{Number of columns}})
\end{displaymath}
with $\nu$ being the value type. The value type can either be a value variable or a concrete value.

Value variables always appear if we know that a certain relationship holds, but do not know the concrete values yet.
For example, when we multiply two matrices $A\in\mathbb{R}^{a\times b}$ and $B\in\mathbb{R}^{b\times c}$ we know that the result is $A\times B = C \in \mathbb{R}^{a\times c}$, without having knowledge about the actual values of $a$ and $c$.

The matrix size inference is incorporated into the HM type inference by adding some logic to the \code{unify} function.
Whenever we encounter a matrix type during the unification process, we call a \code{unifyValue} function on the two row and column values.
The \code{unifyValue} function works similarly to the \code{unify} function.
First, the function resolves the value expression, thus substituting value variables with their assigned values.
Then, if at least one of the resolved value expressions is still a value variable, then the union is constructed and the corresponding value variable dictionary entry is updated.
If both resolved expressions are equal, then this value is returned and otherwise a value mismatch error is thrown.

\subsection{Intermediate Representation}
\label{sec:intermediaterepresentation}

After parsing and typing of the source code is done, it is translated into an intermediate representation.
The additional abstraction layer allows Gilbert to apply language independent optimization in a coherent manner and independently of the actually used front end language.
This implementation aspect gives the flexibility to easily extend Gilbert to support other linear algebra languages as well.
A higher-level abstraction of the mathematical operations holds more potential for algebraic optimization, too.

The intermediate format consists of a set of operators to represent the different linear algebra operations.
Every operator has a distinct result type and a set of parameters which are required as inputs.
The set of intermediate operators can be distinguished into three categories: \emph{Creation operators}, \emph{transformation operators} and \emph{output operators}.

\subsubsection{Creation Operators}

Creation operators generate or load some data.
The \code{load} operator takes a path to a stored matrix on disk and the corresponding number of rows and columns as input parameters.
It then reads the stored data and loads the matrix into the program context.
The \code{eye} operator, known from MATLAB, generates an identity matrix of the requested size, number of rows and columns.
The operator also supports non quadratic result shapes.
\code{zeros} generates a matrix of the given size which is initialized with zeros.
\code{Randn} takes the number of rows and columns of the resulting matrix and the mean and the standard deviation of a Gauss distribution.
The specified Gauss distribution is used to generate random values for the resulting matrix.

\subsubsection{Transformation Operators}

The transformation operators constitute the main abstraction of the linear algebra operations.
They group operations with similar properties and thus allow an easier reasoning and optimization of the underlying program.

The \code{UnaryScalarTransformation} takes a single scalar value and applies an unary operation on it.
The \code{ScalarScalarTransformation} constitutes a binary operation on scalar values whereas \code{ScalarMatrixTransformation} and \code{MatrixScalarTransformation} represent a binary operation between a scalar and a matrix value.
The \code{VectorwiseMatrixTransformation} applies an operation on each row vector of the given matrix.
A vectorwise operation produces a scalar value for each row vector.
Similar to the vectorwise operations, the \code{AggregateMatrixTransformation} applies an operation to all matrix entries producing a single scalar result value.

The iteration mechanism is represented by the \code{FixpointIterationMatrix} and \\\code{FixpointIterationCellArray} operators.
The former operator is used for a fixpoint operation on matrices and the latter on cell arrays.
Both operators follow the semantics and have the same parameters as the fixpoint abstraction presented in \cref{eqn:fixpoint}.

\subsubsection{Writing Operators}

The writing operators are used to make the computed results accessible to the user by writing them back to disk.
There exists a writing operation for each supported type: \code{WriteMatrix}, \code{WriteScalar}, \code{WriteString}, \code{WriteCellArray} and \code{WriteFunction}.

\subsection{Gilbert Optimizer}
\label{sec:gilbertOptimizer}

The Gilbert optimizer applies algebraic optimizations to a Gilbert program.
The optimizer exploits equivalence transformations which result from the commutative and associative properties of linear algebra operations.
It works on the intermediate format of a program, which provides an appropriate high-level abstraction.

\subsubsection{Matrix Multiplication Reordering}

Matrix multiplications belong to the most expensive operations in linear algebra programs in terms of computational complexity as well as space complexity.
Intermediate results of successive matrix multiplications can easily exceed the memory capacity and thus rendering its computation infeasible.
However, a smart execution order can sometimes avoid the materialization of excessivly large matrices.

The best execution order of successive multiplications is the one that minimizes the maximum size of intermediate results.
In order to determine the best execution order, the optimizer first extracts all matrix multiplications with more than $2$ operands.
Then, it will calculate for each evaluation order the maximum size of all occurring intermediate results.
In order to do this calculation, the optimizer relies on the operands' automatically inferred matrix sizes, as described in \cref{sec:MatrixDimensionInference}.
At last, it will pick the execution order with the minimal maximum intermediate matrix size.

\subsubsection{Transpose Pushdown}

Transpose pushdown tries to move the transpose operations as close to the matrix input as possible.
Thereby, consecutive transpose operations accumulate at the inputs and unnecessary operations erase themselves.
An example is given in \cref{lst:pushdown}.

\begin{listing}[!h]
  \begin{CenteredBox}
    \begin{lstlisting}[language=Matlab]
C = A'*B;
E = (C * D')';
    \end{lstlisting}
  \end{CenteredBox}
  \caption{Transpose pushdown can eliminate unnecessary transpose operations occurring in linear algebra programs.}
  \label{lst:pushdown}
\end{listing}

By inserting $C$ into $E$, the expression $E=(A^T BD^T)^T$ is obtained. This term is equivalent to $DB^T A$.
The latter formulation contains only one transpose operation.

Usually multiple transpose operations occur because they are written for convenience reasons at various positions in the code.
Moreover, in complex programs it is possible that the programmer loses track of them or simply is unaware of the optimization potential.
Therefore, transpose pushdown might be a beneficial optimization.