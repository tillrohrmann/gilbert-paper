%!TEX root=paper.tex
\section{Introduction}

Key component of modern big data solutions are sophisticated analysis algorithms. 
Unfortunately, the search for useful patterns and peculiarities in large data sets resembles the search for a needle in a haystack. 
This challenge requires tools that are able to analyze vast amounts of data quickly. 
Many of these tools are based on statistics to extract interesting features. 

It is beneficial to apply these statistical means to the complete data set instead of smaller chunks. 
Even if the chunks cover the complete data set, important correlations between data points might get lost if chunks are treated individually. 
Moreover, the statistical tools improve their descriptive and predictive results by getting fed more data. 
The more data is available, the more likely it is that noise cancels out and that significant patterns manifest. 
However, these benefits come at the price of an increased computing time, which requires fast computer systems to make computations feasible. 

Analysis tools traditionally do not scale well for vast data sets.
Because of the exponential data growth, analytic capacities have to improve at a similar speed to keep analyses feasible. 
Usually, one tries to speed up computers by vertical or horizontal scaling.
To scale vertically means that we add more resources to a single computer.
For example, the main memory size or the CPU frequency of a computer can be increased to improve computational power.
In contrast to that, horizontal scaling means to add more computer nodes to a system.
By having more than one node, the work can be split up and distributed across the nodes.

The emerging multi-core and distributed systems pose new challenges for programmers.
Since they have to be able to reason about interwoven parallel control flows, parallel program development is highly cumbersome and error-prone.
Therefore, new programming models are conceived, a development that relieves the programmer from the tedious low-level tasks related to parallelization such as load-balancing, scheduling of parallel tasks, and fault recovery.
With these new models, programmers can concentrate on the actual algorithm and use case rather than reasoning about distributed systems. 
These are the reasons why Google's MapReduce~\cite{dean:c2008a} framework and its open source re-implementation Hadoop~\cite{hadoop:2008a} became so popular among scientists as well as engineers.

However, MapReduce and other frameworks force the user to express the program in a certain way, which is often not natural or intuitive to a user coming from a different domain.
Especially, in the field of data analytics and machine learning programs are usually expressed in a mathematical form.
Therefore, systems such as MATLAB~\cite{matlab} and R~\cite{r:1993a} are widely used and recognized for their fast prototyping capabilities and their extensive mathematical libraries.
However, these linear algebra systems lack proper support for automatic parallelization on large clusters and are thus restricting the user to a single workstation.
Therefore, the amount of processable data is limited to the size of the main memory, which constitutes a serious drawback for real-world applications.

\begin{figure}[t!]
\centering
\includegraphics[height=0.175\paperheight]{images/systemArchitecture.png}
\caption{The layered system architecture of Gilbert consisting of the language, intermediate and runtime layer.}
\label{fig:systemArchitecture}
\end{figure}

As a solution we propose Gilbert, a distributed sparse linear algebra environment whose name is a homage to William Gilbert Strang.
Gilbert provides a MATLAB-like language for distributed sparse linear algebra operations. It has a layered architecture, which is shown in Figure \ref{fig:systemArchitecture}. The first layer is the language layer. It contains all functionality to parse the given Gilbert code and to compile it into an intermediate representation (IR). The second layer is the intermediate layer and it receives the IR of the Gilbert code. The intermediate format is the ideal representation to apply language independent high-level transformations. The Gilbert optimizer applies several algebraic optimizations prior to the generation of the execution plan. The execution plan generator translates the optimized IR into a specific execution plan, depending on the selected execution engine. Once the program has been translated into an execution engine's specific plan, it is executed on the respective back end. 

Our main contributions are:
\begin{itemize}
 \item Gilbert allows to write MATLAB-like code for sparse linear algebra and execute it on massively parallel dataflow systems.
 \item Its expressiveness allows to quickly develop scalable algorithms to analyze web-scale data.
 \item We introduce a novel fixed-point operator which replaces loops by recursion and can be efficiently parallelized.
 \item Furthermore, we demonstrate that dataflow optimizers can be used to automatically select a good matrix multiplication strategy. 
\end{itemize}

The rest of this paper is structured as follows.
In \Cref{sec:gilbertFeatures}, Gilbert's language and its features are described.
\Cref{sec:gilbertRuntime} presents how linear algebra operations are mapped to a dataflow system. Gilbert's performance and scalability is evaluated in \Cref{sec:evaluation}.
Related work is covered in \Cref{sec:relatedWork} before the work is concluded in \Cref{sec:conclusion}.